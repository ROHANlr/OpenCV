import cv2
import numpy as np

def main(video_path):
    # Load the video
    video_path = "C:\\Users\\rinku\\Downloads\\Untitled video - Made with Clipchamp (1).mp4"
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print("Error: Could not open video.")
        return

    # Create FAST detector
    fast = cv2.FastFeatureDetector_create()

    # Create ORB detector
    orb = cv2.ORB_create()

    # Create BFMatcher for descriptor matching
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

    # Initialize previous frame and keypoints
    prev_frame = None
    prev_keypoints = None
    prev_descriptors = None

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Convert the frame to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Detect keypoints using FAST
        keypoints = fast.detect(gray, None)

        # Compute descriptors using ORB
        keypoints, descriptors = orb.compute(gray, keypoints)

        if prev_frame is not None:
            # Match descriptors with previous frame
            matches = bf.match(prev_descriptors, descriptors)

            # Sort matches by distance
            matches = sorted(matches, key=lambda x: x.distance)

            # Draw matches
            match_img = cv2.drawMatches(prev_frame, prev_keypoints, frame, keypoints, matches[:50], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

            # Display the matches
            cv2.imshow("Feature Matches", match_img)

        # Update previous frame and keypoints
        prev_frame = frame
        prev_keypoints = keypoints
        prev_descriptors = descriptors

        # Stop if 'q' key is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    video_path = "drone_footage.mp4"  # Replace with the path to your drone footage
    main(video_path)
